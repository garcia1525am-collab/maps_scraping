# Google Maps Business Scraper PRO v3.0

**Sistema avanzado de extracciÃ³n de datos de negocios de Google Maps con persistencia automÃ¡tica y recuperaciÃ³n de sesiones**

## ğŸ¯ CaracterÃ­sticas Principales

### Nunca MÃ¡s Pierdas Tus Datos
- **Auto-guardado inteligente**: Cada 5 negocios procesados
- **Respaldo automÃ¡tico**: Cada 2 minutos durante la extracciÃ³n
- **Persistencia mÃºltiple**: Local (JSON/CSV) + MySQL opcional
- **RecuperaciÃ³n de sesiones**: ContinÃºa donde lo dejaste usando el ID de sesiÃ³n
- **Manejo de interrupciones**: Guarda datos automÃ¡ticamente si se cierra inesperadamente

### ExtracciÃ³n Avanzada
- **Scroll automÃ¡tico**: Carga resultados de forma inteligente
- **MÃºltiples selectores**: MÃ¡xima compatibilidad con cambios de Google Maps
- **Datos completos**: Nombre, calificaciÃ³n, reviews, telÃ©fono, website, direcciÃ³n, tipo
- **BÃºsquedas ilimitadas**: Acumula datos de mÃºltiples bÃºsquedas en la misma sesiÃ³n

### Interfaz Moderna
- **Web app con Streamlit**: Interfaz visual e intuitiva
- **CLI tradicional**: Para usuarios que prefieren lÃ­nea de comandos
- **Analytics en tiempo real**: GrÃ¡ficos y estadÃ­sticas de los datos extraÃ­dos
- **ExportaciÃ³n mÃºltiple**: CSV por criterios, bÃºsquedas individuales, etc.

## ğŸš€ InstalaciÃ³n RÃ¡pida

### 1. Clona o descarga los archivos
```bash
# Clona el repositorio o descarga todos los archivos Python
# AsegÃºrate de tener todos estos archivos en la misma carpeta:
# - database_manager.py
# - scraper_enhanced.py  
# - streamlit_app_enhanced.py
# - setup.py
# - requirements.txt
```

### 2. Ejecuta la instalaciÃ³n automÃ¡tica
```bash
python setup.py
```

El script de setup automÃ¡ticamente:
- Instala todas las dependencias necesarias
- Configura MySQL (opcional)
- Crea directorios necesarios
- Verifica Chrome/ChromeDriver
- Crea scripts de ejecuciÃ³n
- Configura el sistema de persistencia

### 3. Ejecuta el scraper

**OpciÃ³n 1: Interfaz Web (Recomendada)**
```bash
# Linux/Mac
./run_streamlit.sh

# Windows
run_streamlit.bat

# Manual
streamlit run streamlit_app_enhanced.py
```

**OpciÃ³n 2: LÃ­nea de Comandos**
```bash
# Linux/Mac
./run_cli.sh

# Windows  
run_cli.bat

# Manual
python scraper_enhanced.py
```

## ğŸ—„ï¸ ConfiguraciÃ³n de MySQL (Opcional)

MySQL proporciona persistencia avanzada pero no es obligatorio. Sin MySQL, el sistema usa almacenamiento local.

### InstalaciÃ³n de MySQL

**Ubuntu/Debian:**
```bash
sudo apt update
sudo apt install mysql-server
sudo systemctl start mysql
sudo systemctl enable mysql
```

**CentOS/RHEL:**
```bash
sudo yum install mysql-server
sudo systemctl start mysqld
sudo systemctl enable mysqld
```

**Windows:**
- Descarga MySQL Community Server desde mysql.com
- Ejecuta el instalador
- Configura usuario root con contraseÃ±a

**macOS:**
```bash
brew install mysql
brew services start mysql
```

### ConfiguraciÃ³n Inicial
```bash
# Configurar MySQL (solo primera vez)
sudo mysql_secure_installation

# Crear usuario (opcional)
mysql -u root -p
CREATE USER 'scraper_user'@'localhost' IDENTIFIED BY 'tu_password';
GRANT ALL PRIVILEGES ON google_maps_scraper.* TO 'scraper_user'@'localhost';
FLUSH PRIVILEGES;
EXIT;
```

## ğŸ“– GuÃ­a de Uso

### 1. PreparaciÃ³n de URLs

Ve a Google Maps y realiza tu bÃºsqueda:

**Ejemplos de bÃºsquedas vÃ¡lidas:**
- `restaurantes mexicanos cdmx`
- `dentistas cerca de mi ubicaciÃ³n`
- `hoteles en cancÃºn`
- `ferreterÃ­as zona norte`

**Copia la URL completa que aparece en tu navegador despuÃ©s de la bÃºsqueda:**
```
https://www.google.com/maps/search/restaurantes+mexicanos+cdmx/@19.4326,-99.1332,13z/data=...
```

### 2. Usando la Interfaz Web

1. **Ejecuta**: `streamlit run streamlit_app_enhanced.py`
2. **Configura MySQL** (opcional) en el panel lateral
3. **Ingresa la URL** de tu bÃºsqueda de Google Maps
4. **Nombra tu bÃºsqueda**: Ej: "restaurantes_cdmx"
5. **Selecciona cantidad** de resultados (recomendado: 15-50)
6. **Inicia el scraping**

El sistema automÃ¡ticamente:
- Guarda cada 5 negocios extraÃ­dos
- Crea respaldos cada 2 minutos  
- Genera un ID de sesiÃ³n Ãºnico
- Permite continuar si se interrumpe

### 3. Usando la LÃ­nea de Comandos

```bash
python scraper_enhanced.py
```

El scraper te preguntarÃ¡:
- Si usar MySQL
- URL de bÃºsqueda
- Cantidad de resultados
- Nombre de la bÃºsqueda
- ID de sesiÃ³n (para continuar una sesiÃ³n anterior)

### 4. RecuperaciÃ³n de Sesiones

Si el proceso se interrumpe:

**En interfaz web:**
- Anota tu ID de sesiÃ³n (se muestra en pantalla)
- Reinicia la aplicaciÃ³n
- En "GestiÃ³n de Sesiones" ingresa tu ID
- Click en "Cargar SesiÃ³n"

**En lÃ­nea de comandos:**
- Ejecuta el scraper nuevamente
- Cuando pregunte por ID de sesiÃ³n, ingresa el mismo ID anterior
- El sistema recuperarÃ¡ automÃ¡ticamente tus datos

## ğŸ“Š Estructura de Datos

### InformaciÃ³n ExtraÃ­da por Negocio:
- **Nombre**: Nombre del negocio
- **CalificaciÃ³n**: PuntuaciÃ³n (1-5 estrellas)
- **NÃºmero de reviews**: Cantidad de reseÃ±as
- **Tipo**: CategorÃ­a del negocio
- **DirecciÃ³n**: DirecciÃ³n fÃ­sica completa
- **TelÃ©fono**: NÃºmero de contacto
- **Website**: Sitio web oficial
- **Email**: Correo electrÃ³nico (cuando disponible)
- **Fecha de extracciÃ³n**: CuÃ¡ndo se obtuvo el dato
- **BÃºsqueda**: A quÃ© bÃºsqueda pertenece
- **ID de sesiÃ³n**: Identificador Ãºnico de la sesiÃ³n

### Archivos Generados:
- **`negocios_[nombre_busqueda].csv`**: Datos de una bÃºsqueda especÃ­fica
- **`session_[session_id]_[timestamp].csv`**: Datos completos de la sesiÃ³n
- **`session_data/`**: Respaldos automÃ¡ticos en JSON
- **`EMERGENCY_backup_*.csv`**: Respaldos de emergencia

## ğŸ—„ï¸ Base de Datos MySQL

### Tablas Creadas AutomÃ¡ticamente:

**`negocios`**: Almacena todos los negocios extraÃ­dos
```sql
- id (PK)
- nombre, calificacion, num_reviews, tipo
- direccion, telefono, website, email  
- busqueda, fecha_extraccion
- url_google_maps, session_id
- created_at, updated_at
```

**`historial_busquedas`**: Registro de todas las bÃºsquedas realizadas
```sql
- id (PK)
- busqueda, url, resultados, fecha
- parametros (JSON), duracion_segundos
```

**`respaldos_sesion`**: Respaldos automÃ¡ticos de sesiones
```sql
- id (PK) 
- session_id, datos (JSON), timestamp
- tipo_respaldo (auto/manual)
```

### Consultas Ãštiles:
```sql
-- Ver todos los negocios con telÃ©fono
SELECT nombre, telefono, direccion FROM negocios WHERE telefono != 'No disponible';

-- EstadÃ­sticas por bÃºsqueda
SELECT busqueda, COUNT(*) as total, AVG(calificacion) as promedio
FROM negocios 
WHERE calificacion IS NOT NULL 
GROUP BY busqueda;

-- Negocios mejor calificados
SELECT nombre, calificacion, num_reviews, direccion 
FROM negocios 
WHERE calificacion >= 4.5 
ORDER BY calificacion DESC, CAST(num_reviews AS UNSIGNED) DESC;
```

## ğŸ› ï¸ SoluciÃ³n de Problemas

### Error: Chrome no encontrado
```bash
# Reinstalar undetected-chromedriver
pip uninstall undetected-chromedriver
pip install undetected-chromedriver

# O especificar ruta de Chrome manualmente en el cÃ³digo
```

### Error: MySQL conexiÃ³n fallÃ³
- Verifica que MySQL estÃ© ejecutÃ¡ndose: `sudo systemctl status mysql`
- Confirma usuario y contraseÃ±a: `mysql -u root -p`
- El sistema funcionarÃ¡ solo con almacenamiento local si falla MySQL

### Error: MÃ³dulo no encontrado
```bash
# Reinstalar dependencias
pip install -r requirements.txt

# O instalar manualmente
pip install streamlit pandas plotly selenium undetected-chromedriver mysql-connector-python
```

### Scraper se detiene o es bloqueado
- Usa pausas mÃ¡s largas entre requests (modifica `time.sleep()` en el cÃ³digo)
- Cambia User-Agent en `scraper_enhanced.py`
- Usa diferentes rangos de IP o proxies
- Respeta los lÃ­mites de rate limiting de Google

### Recuperar datos perdidos
```bash
# Buscar respaldos locales
ls session_data/

# Cargar sesiÃ³n especÃ­fica
python scraper_enhanced.py
# Ingresa el session_id cuando lo solicite

# Verificar en MySQL
mysql -u root -p
USE google_maps_scraper;
SELECT session_id, timestamp FROM respaldos_sesion ORDER BY timestamp DESC;
```

## âš¡ OptimizaciÃ³n y Rendimiento

### Configuraciones Recomendadas:
- **Resultados por bÃºsqueda**: 15-50 (evita bÃºsquedas muy grandes)
- **Pausas entre requests**: 2-3 segundos
- **Auto-guardado**: Cada 5 negocios (configurable)
- **Respaldo automÃ¡tico**: Cada 2 minutos

### Para BÃºsquedas Grandes:
1. Divide en mÃºltiples sesiones mÃ¡s pequeÃ±as
2. Usa diferentes criterios geogrÃ¡ficos
3. Programa pausas largas entre bÃºsquedas
4. Monitorea el uso de memoria

## ğŸ“ Estructura del Proyecto

```
google-maps-scraper-pro/
â”œâ”€â”€ database_manager.py          # Gestor de MySQL y persistencia
â”œâ”€â”€ scraper_enhanced.py         # Scraper principal con auto-guardado
â”œâ”€â”€ streamlit_app_enhanced.py   # Interfaz web moderna
â”œâ”€â”€ setup.py                    # Script de instalaciÃ³n
â”œâ”€â”€ requirements.txt            # Dependencias
â”œâ”€â”€ README.md                   # Esta documentaciÃ³n
â”œâ”€â”€ config.json                 # ConfiguraciÃ³n generada por setup
â”œâ”€â”€ session_data/               # Respaldos locales automÃ¡ticos
â”œâ”€â”€ exports/                    # Exportaciones CSV
â”œâ”€â”€ logs/                       # Archivos de log (futuro)
â””â”€â”€ temp_chrome_profiles/       # Perfiles temporales de Chrome
```

## ğŸ”’ Consideraciones de Seguridad y Legalidad

### Uso Responsable:
- **Respeta los tÃ©rminos de servicio** de Google Maps
- **No hagas scraping masivo** que pueda sobrecargar los servidores
- **Usa pausas apropiadas** entre requests
- **No redistribuyas datos personales** sin autorizaciÃ³n
- **Verifica la legalidad** en tu jurisdicciÃ³n

### Buenas PrÃ¡cticas:
- Limita a datos pÃºblicos disponibles en Google Maps
- No extraigas mÃ¡s datos de los necesarios
- Respeta robots.txt y polÃ­ticas de rate limiting
- Considera usar APIs oficiales cuando estÃ©n disponibles
- MantÃ©n actualizadas las dependencias de seguridad

## ğŸ†˜ Soporte y Contribuciones

### En caso de problemas:
1. Verifica que tienes la versiÃ³n mÃ¡s reciente
2. Revisa la secciÃ³n "SoluciÃ³n de Problemas"
3. Verifica los logs en `session_data/`
4. Prueba con una bÃºsqueda mÃ¡s pequeÃ±a primero

### CaracterÃ­sticas de la versiÃ³n actual:
- âœ… Auto-guardado y recuperaciÃ³n de sesiones
- âœ… Soporte para MySQL + almacenamiento local  
- âœ… Interfaz web moderna con Streamlit
- âœ… Manejo robusto de interrupciones
- âœ… ExportaciÃ³n mÃºltiple de datos
- âœ… Analytics y visualizaciones

### PrÃ³ximas mejoras planificadas:
- ğŸ”„ Soporte para proxies y rotaciÃ³n de IP
- ğŸ“Š Dashboard de mÃ©tricas en tiempo real
- ğŸŒ API REST para integraciÃ³n externa
- ğŸ“± VersiÃ³n mobile-responsive
- ğŸ¤– DetecciÃ³n automÃ¡tica de cambios en Google Maps

---

**âš ï¸ Disclaimer**: Este software es para propÃ³sitos educativos y de investigaciÃ³n. El uso debe cumplir con los tÃ©rminos de servicio de Google y las leyes locales aplicables. Los desarrolladores no se hacen responsables del mal uso de esta herramienta.

**ğŸ“§ Soporte**: Para problemas tÃ©cnicos, verifica primero que tengas todas las dependencias instaladas y que MySQL (si lo usas) estÃ© funcionando correctamente.